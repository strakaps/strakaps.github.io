[{"authors":null,"categories":["statistical learning"],"content":"Lasso \u0026amp; glinternet Every Data Scientist and her dog know linear and logistic regression. The majority will probably also know that these models have regularized versions, which increase predictive performance by reducing variance (at the cost of a small increase in bias). Choosing L1-regularization (Lasso) even gets you variable selection for free. The theory behind these models is covered expertly in The Elements of Statistical Learning (for an easier version, see An Introduction to Statistical Learning), and implemented nicely in the packages glmnet for R and scikitlearn for Python.\nFew people, however, have heard about glinternet, which is a powerful extension of the Lasso model:\n glinternet adds pairwise variable interactions into the Lasso model, and selects these automatically.\n It’s a linear model, and thus easily interpretable. Its computational complexity is the same as penalized regression: \\(\\mathcal O(Nm)\\) where there are \\(N\\) rows and \\(m\\) variables1. Thus it handles problems of the same size as (deep) neural networks, potentially with tens of thousands of variables. It should be stressed here that for a thousand variables there are almost 500,000 pairwise interactions that glinternet checks! For structured data, logistic regression is a very useful benchmark model, which can be on par with sophisticated deep learning models even for huge datasets. The glinternet model is more flexible than logistic regression, and is just as interpretable.\n A glinternet tutorial Let’s look at the car90 dataset in the rpart package. It has 25 categorical and 8 continuous predictors, and a continuous outcome (Price). We fit a glinternet model to it, which is a linear model containing all possible pairwise interactions.\nInteractions A linear model without interactions is usually written as\n\\[y = \\beta_0 + \\sum_k \\beta_k X_k + \\varepsilon\\]\nwhere \\(\\beta_0\\) is the intercept, \\(X_k\\) are predictor variables, \\(\\beta_k\\) the coefficients and \\(\\varepsilon\\) a model error. We will use categorical variables, so we need to group the variables and coefficients with their categories:\n\\[y = \\beta_0 + \\sum_{i=1}^m \\sum_{l=1}^{L_i} \\beta_{i,l} X_{i,l} + \\varepsilon\\] where\n \\(m\\) is the number of predictors \\(X_1, \\ldots, X_m\\) \\(L_i\\) is the number of levels of \\(X_i\\) if \\(X_i\\) is categorical, and 1 otherwise \\((X_{i,1}, \\ldots, X_{i,L_i})\\) are 0-1 dummy variables representing the categories of \\(X_i\\) (one-hot encoded)  A pairwise interaction model contains all possible pairwise products of the predictors:\n\\[y = \\beta_0 + \\sum_{l=1}^{L_i} \\sum_{i=1}^m \\beta_{i,l}, X_{i,l} + \\sum_{1 \\le i\u0026lt;j \\le m} \\sum_{l=1}^{L_i} \\sum_{k=1}^{L_j} \\theta_{i,j,l,k} X_{i,l} X_{j,k}\\]\nInteractions, e.g. between variables \\(X_i\\) and \\(X_j\\), occur when the effect of \\(X_j\\) on \\(y\\) will vary depending on the level (or value) of \\(X_i\\). In that case, some of the values \\(\\theta_{i,j, \\cdot, \\cdot}\\) will be non-zero.\nSelection of variables and interactions The L1 regularization is known as the lasso and produces sparsity. glinternet uses a group lasso for the variables and variable interactions, which introduces the following strong hierarchy: An interaction between \\(X_i\\) and \\(X_j\\) can only be picked by the model if both \\(X_i\\) and \\(X_j\\) are also picked. In other words, interactions between two predictors are not considered unless both predictors have non-zero coefficients in the model. The details are in the original paper.\n  Fitting glinternet Unfortunately, glinternet’s “API” is not super user friendly… the first challenge is to bring the data into a form that glinternet accepts: The categorical variables need to be (somewhat un-R-like) coded as integers starting from 0. We also need to construct a numLevels vector containing the number of levels \\(L_1, \\ldots, L_m\\) in each column if the column is categorical, and 1 else:\nlibrary(dplyr) # Model2 contains model names, which aren\u0026#39;t useful here df \u0026lt;- rpart::car90 %\u0026gt;% select(-Model2) # drop rows with empty outcomes df \u0026lt;- df[!is.na(df$Price), ] y \u0026lt;- df$Price df \u0026lt;- df %\u0026gt;% select(-Price) # impute the median for the continuous variables i_num \u0026lt;- sapply(df, is.numeric) df[, i_num] \u0026lt;- apply(df[, i_num], 2, function(x) ifelse(is.na(x), median(x, na.rm=T), x)) # impute empty categories df[, !i_num] \u0026lt;- apply(df[, !i_num], 2, function(x) { x[x==\u0026quot;\u0026quot;] \u0026lt;- \u0026quot;empty\u0026quot; x[is.na(x)] \u0026lt;- \u0026quot;missing\u0026quot; x }) # get the numLevels vector containing the number of categories X \u0026lt;- df X[, !i_num] \u0026lt;- apply(X[, !i_num], 2, factor) %\u0026gt;% as.data.frame() numLevels \u0026lt;- X %\u0026gt;% sapply(nlevels) numLevels[numLevels==0] \u0026lt;- 1 # make the categorical variables take integer values starting from 0 X[, !i_num] \u0026lt;- apply(X[, !i_num], 2, function(col) as.integer(as.factor(col)) - 1) A single glinternet model is fitted with the function glinternet; here, we directly fit a 10-fold Cross-Validated model:\nlibrary(glinternet) set.seed(1001) cv_fit \u0026lt;- glinternet.cv(X, y, numLevels) plot(cv_fit) We see the MSE plotted against the decreasing values of regularization parameter lambda.\ni_1Std \u0026lt;- which(cv_fit$lambdaHat1Std == cv_fit$lambda) It is common not to pick the lambda corresponding to the lowest estimate of cross-validation error, but to err on the side of more regularization. So we are happy with a larger lambda with CV error estimate below the minimum plus one standard deviation. This lambda has index i_1Std = 22. Its coefficients \\(\\beta_{i,l}\\) and \\(\\theta_{i,j,l,k}\\) can be extracted by running\ncoefs \u0026lt;- coef(cv_fit$glinternetFit)[[i_1Std]] coefs is a list of 4 items: mainEffects, mainEffectsCoef, interactions and interactionsCoef.\nLet’s look at the part without interactions first: The main effects identified are\ncoefs$mainEffects ## $cat ## [1] 3 ## ## $cont ## [1] 5 7 9 12 20 22 11 which are the indices of the categorical variables and the continuous variables, in order as they occur in the data. We get the indices via\nidx_num \u0026lt;- (1:length(i_num))[i_num] idx_cat \u0026lt;- (1:length(i_num))[!i_num] names(numLevels)[idx_cat[coefs$mainEffects$cat]] ## [1] \u0026quot;Rim\u0026quot; names(numLevels)[idx_num[coefs$mainEffects$cont]] ## [1] \u0026quot;Frt.Leg.Room\u0026quot; \u0026quot;Gear.Ratio\u0026quot; \u0026quot;HP\u0026quot; \u0026quot;Length\u0026quot; ## [5] \u0026quot;Tank\u0026quot; \u0026quot;Weight\u0026quot; \u0026quot;Height\u0026quot; The coefficients for these variables are:\ncoefs$mainEffectsCoef ## $cat ## $cat[[1]] ## [1] 357.6320 -8221.4669 6589.1535 -36595.3391 118.0856 -920.4584 ## ## ## $cont ## $cont[[1]] ## [1] 35.48628 ## ## $cont[[2]] ## [1] 314.3327 ## ## $cont[[3]] ## [1] -477.2347 ## ## $cont[[4]] ## [1] 9.059015 ## ## $cont[[5]] ## [1] 507.8227 ## ## $cont[[6]] ## [1] 1.366189 ## ## $cont[[7]] ## [1] 104.6502 (I would have expected all of these to be positive; one should check why HP has a negative coefficient.)\nNow for the interaction pairs:\ncoefs$interactions ## $catcat ## NULL ## ## $contcont ## [,1] [,2] ## [1,] 5 9 ## [2,] 11 20 ## ## $catcont ## [,1] [,2] ## [1,] 3 5 The above means:\n There is no interaction between the categorical variables (unsurprising because we only identified one. If there was an interaction pair, we would access it via coefs$interactionsCoef$catcat, giving a list of matrices, one matrix of dimension \\(L_i \\times L_j\\) for each pair.) Two pairs of continuous variables have interactions: (5,9) and (11,20), which are (Frt.Leg.Room, HP) and (Height, Tank). The coefficients for these interactions are  coefs$interactionsCoef$contcont ## [[1]] ## [1] 13.66277 ## ## [[2]] ## [1] -6.634724  There is one interaction between categorical variable 3 and continuous variable 5, which are Rim and Frt.Leg.Room. The coefficients for this interaction are:  coefs$interactionsCoef$catcont ## [[1]] ## [1] -164.0751 37.7502 -324.6745 741.9752 -158.0835 -132.8923 Our simple interaction network looks like this:\nThe model has a root mean squared error (RMSE) on validation data of\nsqrt(cv_fit$cvErr[[i_1Std]]) ## [1] 3411.904  Compare to linear regression To quantify how much interactions have contributed to predictive power, we now fit a glmnet model. The best CV mean-squared error for the glmnet model is higher than the mean-squared error for glinternet:\ndf$Price \u0026lt;- y X \u0026lt;- model.matrix(Price ~ . - 1, df) library(glmnet) cv_glmnet \u0026lt;- cv.glmnet(X,y) sqrt(min(cv_glmnet$cvm)) ## [1] 4238.202  Take-home message When you’re using logistic or linear regression with Lasso regularization as a baseline, and your next step is to see if adding interactions improve predictive power: try glinternet!\n References Learning Interactions via Hierarchical Group-Lasso Regularization. Michael Lim \u0026amp; Trevor Hastie\n   Though for this to be true, I believe you have to limit the “interaction search space” via the screenLimit parameter.↩\n   ","date":1539388800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539388800,"objectID":"e8baeef4dd71892f97cc012f8839f97c","permalink":"https://strakaps.github.io/post/glinternet/","publishdate":"2018-10-13T00:00:00Z","relpermalink":"/post/glinternet/","section":"post","summary":"Lasso \u0026amp; glinternet Every Data Scientist and her dog know linear and logistic regression. The majority will probably also know that these models have regularized versions, which increase predictive performance by reducing variance (at the cost of a small increase in bias). Choosing L1-regularization (Lasso) even gets you variable selection for free. The theory behind these models is covered expertly in The Elements of Statistical Learning (for an easier version, see An Introduction to Statistical Learning), and implemented nicely in the packages glmnet for R and scikitlearn for Python.","tags":["R","Machine Learning"],"title":"Add Interactions to Regularized Regression","type":"post"},{"authors":["Peter Straka"],"categories":null,"content":"","date":1533045600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533045600,"objectID":"c8b2a573c64de7fb91f8b8eb2e494d53","permalink":"https://strakaps.github.io/publication/voffpe/","publishdate":"2018-08-01T00:00:00+10:00","relpermalink":"/publication/voffpe/","section":"publication","summary":"Continuous Time Random Walk models (CTRW) of anomalous diffusion are studied, where the anomalous exponent β(x)∈(0,1) varies in space. This type of situation occurs e.g. in biophysics, where the density of the intracellular matrix varies throughout a cell. Scaling limits of CTRWs are known to have probability distributions which solve fractional Fokker-Planck type equations (FFPE). This correspondence between stochastic processes and FFPE solutions has many useful extensions e.g. to nonlinear particle interactions and reactions, but has not yet been sufficiently developed for FFPEs of the 'variable order' type with non-constant β(x). In this article, variable order FFPEs (VOFFPE) are derived from scaling limits of CTRWs. The key mathematical tool is the 1-1 correspondence of a CTRW scaling limit to a bivariate Langevin process, which tracks the cumulative sum of jumps in one component and the cumulative sum of waiting times in the other. The spatially varying anomalous exponent is modelled by spatially varying β(x)-stable Levy noise in the waiting time component. The VOFFPE displays a spatially heterogeneous temporal scaling behaviour, with generalized diffusivity and drift coefficients whose units are length2/timeβ(x) resp. length/timeβ(x). A global change of the time scale results in a spatially varying change in diffusivity and drift. A consequence of the mathematical derivation of a VOFFPE from CTRW limits in this article is that a solution of a VOFFPE can be approximated via Monte Carlo simulations. Based on such simulations, we are able to confirm that the VOFFPE is consistent under a change of the global time scale.","tags":null,"title":"Variable Order Fractional Fokker-Planck Equations derived from Continuous Time Random Walks","type":"publication"},{"authors":["B Tran","P Straka","MO Falster","KA Douglas","T Britz","LR Jorm"],"categories":null,"content":"See my blog post for this publication.\n","date":1532786400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532786400,"objectID":"f3e6a9adb34f540d6ba5287babbee808","permalink":"https://strakaps.github.io/publication/mja/","publishdate":"2018-07-29T00:00:00+10:00","relpermalink":"/publication/mja/","section":"publication","summary":"  Objectives: To investigate the organisation and characteristics of general practice in Australia by applying novel network analysis methods to national Medicare claims data.\n\n  Design: We analysed Medicare claims for general practitioner consultations during 1994–2014 for a random 10% sample of Australian residents, and applied hierarchical block modelling to identify provider practice communities (PPCs).\n\n  Participants: About 1.7 million patients per year.\n\n  Main outcome measures: Numbers and characteristics of PPCs (including numbers of providers, patients and claims), proportion of bulk-billed claims, continuity of care, patient loyalty, patient sharing.\n\n  Results: The number of PPCs fluctuated during the 21-year period; there were 7747 PPCs in 2014. The proportion of larger PPCs (six or more providers) increased from 32% in 1994 to 43% in 2014, while that of sole provider PPCs declined from 50% to 39%. The median annual number of claims per PPC increased from 5000 (IQR, 40–19 940) in 1994 to 9980 (190–23 800) in 2014; the proportion of PPCs that bulk-billed all patients was lowest in 2004 (21%) and highest in 2014 (29%). Continuity of care and patient loyalty were stable; in 2014, 50% of patients saw the same provider and 78% saw a provider in the same PPC for at least 75% of consultations. Density of patient sharing in a PPC was correlated with patient loyalty to that PPC.\n\n  Conclusions: During 1994–2014, Australian GP practice communities have generally increased in size, but continuity of care and patient loyalty have remained stable. Our novel approach to the analysis of routinely collected data allows continuous monitoring of the characteristics of Australian general practices and their influence on patient care.\n","tags":null,"title":"Overcoming the data drought: exploring general practice in Australia by network analysis of big data","type":"publication"},{"authors":null,"categories":["Public Health"],"content":" See also the MJA podcast episode accompanying this article.\nOur joint work (UNSW CBDRH and Statistics) which analyses Australian patient claim data using big network algorithms is now available on the MJA website. We have processed MBS claims data of 10% of Australians over the years 1994-2014, trying to shed light on the following research questions:\n What is the patient sharing behaviour of general practitioners (GPs): are there any meaningful clusters (called \u0026ldquo;Provider Practice Communities, PPC\u0026rdquo;) of GPs which collaborate and share patients? How have these clusters changed in the course of 20 years? How does Continuity of Care (CoC1) differ between large and small PPCs?  Datasets such as provided by BEACH (Bettering the Evaluation And Care of Health, USYD) would be ideal to tackle these questions, but were discontinued due to lack of funding, and it may take several years until Australia\u0026rsquo;s My Health Record is adopted by enough Australians to generate useful datasets.\nQuestion 1 really is about the structure of information sharing in the Australian health system. We believe we\u0026rsquo;ve found evidence of information sharing within clusters of GPs (PPCs) which resemble the typical sizes of practices of GPs. CoC is a proxy for the sharing of important patient information sharing, which is believed to lead to better health outcomes; but information sharing can also mean that GPs have similar behaviour when referring to specialists or pathology services, among which there may be low-value services such as unwarranted surgical interventions and blood tests.\nBased on the PPCs which we have identified, it is now possible to discover unwarranted variation of good and bad outcomes on the level of PPCs (practices). There are many interesting questions that can be tackled now, and as a first step into this direction, we redefined \u0026ldquo;Continuity of Care\u0026rdquo; on the PPC level, creating an indicator which is high if a patient is loyal to the same practice, rather than the same GP. It seems that the larger a practice, the less loyal patients are to individual GPs; but if loyalty to the same practice is measured, small and large practices seem to fare alike.\nBig Networks The usual approach in network clustering (which was seemingly taken by all previous papers on this topic in the medical literature) is as follows:\n Create a network of GPs only2, where patients only appear as weights on the edges (i.e. project from bipartite to unipartite):  (source: Wikipedia) \n Cluster the GP nodes by maximizing3 modularity:  (source: sciencedirect) \n  The main flaws with this approach are:\n There is no good way to construct edge weights between GPs.4 The resolution limit problem of modularity: The minimum size of discoverable communities grows with the number of nodes $N$ in the network, roughly like $\\sqrt N$. Since we study thousands of GPs, this problem is prohibitive. Modularity assumes that all block structure is assortative, which can be dangerous; moreover even completely random networks can have high modularity.  Using the Python package graph-tool, we were able to:\n Avoid the bipartite projection, even though this meant dealing with millions of nodes (patients and doctors) instead of thousands (doctors only). Fit a hierarchical stochastic blockmodel, which allows detecting much smaller communities. Moreover, the block structure respected bipartiteness, meaning that each block was made up of either doctors only or patients only.  Computations The main challenges were:\n Installing graph-tool: pip and conda are not an option, you have to compile it from source, or install the native Linux / MacOS X packages. RAM usage: graph-tool needed up to 64GB of RAM. We\u0026rsquo;ve used the Katana computational cluster at UNSW and got excellent support along the way. Numerous runs: The hierarchical blockmodelling algorithm converges to a different solution every time; to be somewhat confident to have found a good minimum of the description length, we needed 4 runs of up to 6 hours each, for each of 5 regions.  GitHub Repository The full Python code used for this project, as well as more details on the blockmodelling approach, can be found on the CBDRH GitHub page.\nConclusion Using hierarchical stochastic blockmodelling, it is possible to use data which is routinely collected by GPs to monitor characteristics of Australian general practices. Future research will clarify how these characteristics affect patient care.\n A patient typically seeing the same GP, or GP clinic, experiences high CoC: $${\\rm CoC} = \\frac{\\max \\left\\lbrace n_k \\right \\rbrace}{\\sum_k n_k}$$ where $n_k$ are the numbers of visits made to different PPCs.\n^ In the graph shown, suppose X are the patients and Y the doctors; then the Y-projection is a network of doctors only, with edge weights computed from the number of shared patients.\n^ The picture shows the adjacency matrix, where each row and column corresponds to one node, and a black dot means there is an edge. The red squares represent a grouping of nodes. Modularity, in a nutshell, is the gain in the number of within-group edges achieved by the grouping, compared to the expected number if all edges were reassigned at random.\n^ If you go by the number of shared patients, this discards all patients which have only seen one GP, and makes it impossible to find single GPs. If you go by Jaccard index, this leads to weights between 0 and 1, which is not useful for most community detection algorithms.\n^   ","date":1531699200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531699200,"objectID":"0ec2098c9a3f42a3bebd4e0736b84b52","permalink":"https://strakaps.github.io/post/2018-07-mja-paper/","publishdate":"2018-07-16T00:00:00Z","relpermalink":"/post/2018-07-mja-paper/","section":"post","summary":"See also the MJA podcast episode accompanying this article.\nOur joint work (UNSW CBDRH and Statistics) which analyses Australian patient claim data using big network algorithms is now available on the MJA website. We have processed MBS claims data of 10% of Australians over the years 1994-2014, trying to shed light on the following research questions:\n What is the patient sharing behaviour of general practitioners (GPs): are there any meaningful clusters (called \u0026ldquo;Provider Practice Communities, PPC\u0026rdquo;) of GPs which collaborate and share patients?","tags":["Healthcare","Data Science","Publication","Machine Learning"],"title":"Big Networks in Healthcare","type":"post"},{"authors":null,"categories":["events"],"content":" Last week I had the privilege to participate in the NUS-NUH-MIT DATATHON and Workshop on applications of AI in healthcare with the UNSW Centre for Big Data Research in Health (CBDRH) team (Tim Churches, Mark Hanly, Oisin Fitzgerald and Oluwadamisola Sotade).\nThu \u0026amp; Fri: Workshop \u0026amp; Talks In the workshop \u0026ldquo;Deploying AI Solutions in Real Clinical Practices\u0026rdquo; by Dr Ngiam Kee Yuan (CTO, NUHS) we discussed\n The large NUHS (National University Health System) databases and their storage structure Data security and ownership Applications for access to data The always changing standards of diagnosis codes (ICD9, ICD10, SNOMED, \u0026hellip;) and the problem of matching doctors diagnoses to these codes. In another talk, Hector Yee (@eigenhector) shared some vice ideas on how to use word embeddings as a tool for matching hand-typed diagnoses to ICD10 codes. The importance of getting doctors to trust AI algorithms. Hector presented an interesting approach which iterates between an AI algorithm proposing codes and a doctor validating these. The goal is of course to augment the doctors, not to replace them.  Fri - Sun: Datathon Friday 6pm: Pitching Topics \u0026amp; Forming Teams 23 clinicians pitch topics. We were most interested in a topic presented by Dr Lui Pak Ling (Hematology) and Dr Stella Ang (Anesthesiology) at NUH:\nCurrently-used statistical models predicting the mortality risk of Intensive Care Unit (ICU) patients assume that the importance of prognostic factors does not vary\nResearch Database, a large multi-centre critical care database made available by Philips Healthcare in partnership with the MIT Laboratory for Computational Physiology, they investigated whether the importance of prognostic factors varied in the course of each patient’s stay in ICU. Currently-used predictive models assume that they don’t vary.\n Currently, the mortality risk of ICU (intensive care unit) patients is assessed based on a collection of variables at the time they are presented to the ICU (the so-called Apache score). This score is assumed to be the same during the whole course of stay in the ICU. Is this assumption appropriate, or does the importance of some prognostic variables in fact change over time?\n We joined forces with Siqi Liu, a PhD student at Saw Swee Hock School of Public Health and a member of the organising team for the Datathon who represented our team, and Peng Shen (MOH Holdings Pte Ltd).\nAll of Saturday: Extracting Data We used the eICU Collaborative Research Database. The organisers have made the data available via Google\u0026rsquo;s BigQuery, which was very quick and (almost) 100% reliable. Working in pairs we extracted and cleaned various tables of variables that we used as predictors: comorbidity history, lab results, vitalperiodic and vitalaperiodic, coma score, infusion drugs, dialysis, blood culture, mechanical ventilation, \u0026hellip;\nWe queried the database using\n the BigQuery web interface, the Python API and colab notebooks, or the dbplyr package in R.  Sunday morning: More wrangling Joining all the extracted tables into one big table. The final SQL query was 306 lines long and extracted of 161,988 rows (a cohort of sepsis patients) and 93 transformed and cleaned variables (categorical and continuous) from tables with 224 million rows with 4-51 columns.\nSunday 12pm-3pm: Model fitting As a baseline, we used logistic regression, with L1 penalty for variable selection (using glmnet in R). Virtually all rows had missing data, so we need to impute by median. This didn\u0026rsquo;t seem to work out very well, as e.g. the variables picked at after 2 days in ICU had almost nothing in common with the variables picked for 3 or 4 days in ICU.\nGradient Boosting (using catboost in R) seemed to work stably with the irregularly spaced, high-dimensional data with many missing values. In our preliminary analysis, it seems that \u0026ldquo;age\u0026rdquo; may increase in importance and \u0026ldquo;SaO2\u0026rdquo; (oxygen saturation) may decrease in importance.\nPresentation writing: Teams were judged on a three minute presentation only, and the time limit was strictly enforced (our MC made the audience start clapping after exactly 180 seconds). So the presentation had to be practiced to near perfection, which Dami and Siqi succeeded in doing: The judges placed us first in the track \u0026ldquo;AI for critical care\u0026rdquo; 🎉🎉🎉\nWork to be continued So far, we have fitted individual models to each point in time (day1, day2, \u0026hellip;, day5). This is of course not the ideal way to deal with a longitudinal signal. One ought to try\n Survival analysis with time-dependent coefficients Boosted multivariate trees for longitudinal data  The takeaway Our team is walking away with a preliminary analysis on a cleaned dataset which is likely to result in a publication, and 2 domain experts and 1 other data scientist who are invested in continuing our work. I would say these two days were incredibly well spent!\n","date":1531180800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531180800,"objectID":"787203f3ce652a55f476514c28c71004","permalink":"https://strakaps.github.io/post/nus-mit-datathon/","publishdate":"2018-07-10T00:00:00Z","relpermalink":"/post/nus-mit-datathon/","section":"post","summary":"Last week I had the privilege to participate in the NUS-NUH-MIT DATATHON and Workshop on applications of AI in healthcare with the UNSW Centre for Big Data Research in Health (CBDRH) team (Tim Churches, Mark Hanly, Oisin Fitzgerald and Oluwadamisola Sotade).\nThu \u0026amp; Fri: Workshop \u0026amp; Talks In the workshop \u0026ldquo;Deploying AI Solutions in Real Clinical Practices\u0026rdquo; by Dr Ngiam Kee Yuan (CTO, NUHS) we discussed\n The large NUHS (National University Health System) databases and their storage structure Data security and ownership Applications for access to data The always changing standards of diagnosis codes (ICD9, ICD10, SNOMED, \u0026hellip;) and the problem of matching doctors diagnoses to these codes.","tags":["Data Science","Healthcare","Machine Learning"],"title":"NUS-MIT Datathon","type":"post"},{"authors":null,"categories":["recruitment"],"content":"In the internship, you\u0026rsquo;ll explore the latest machine learning methods such as tree ensemble methods, graphical models and neural networks and compare their performance to what is the current industry standard. A great opportunity to improve your machine learning skills and create valuable insights for the credit risk industry.\nApplications close 20 June, 2018.\nApply here: https://aprintern.org.au/2018/05/21/int-0431/\n","date":1527552000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527552000,"objectID":"1a4ad8ac51e6bfc580793dd741ef5e24","permalink":"https://strakaps.github.io/post/phd-internship-in-machine-learning/","publishdate":"2018-05-29T00:00:00Z","relpermalink":"/post/phd-internship-in-machine-learning/","section":"post","summary":"In the internship, you\u0026rsquo;ll explore the latest machine learning methods such as tree ensemble methods, graphical models and neural networks and compare their performance to what is the current industry standard. A great opportunity to improve your machine learning skills and create valuable insights for the credit risk industry.\nApplications close 20 June, 2018.\nApply here: https://aprintern.org.au/2018/05/21/int-0431/","tags":["Machine Learning","Credit Risk","Banking","Internship"],"title":"PhD internship in Machine Learning","type":"post"},{"authors":null,"categories":["Healthcare"],"content":" What is the network structure of healthcare providers and their practices/clinics? What is their patient sharing pattern? Does sharing of patient information between providers lead to better health outcomes? Do practice size and patient sharing behaviour influence the quality of healthcare?  Australian Medicare claims data contains data1 on tens of thousands of healthcare providers and millions of patients, such as patient characteristics (age, sex, \u0026hellip;) and provider characteristics (specialty, type and frequency of services delivered, bulk-billing behaviour,\n\u0026hellip;).\nThe natural structure of these data is a network, where providers \u0026amp; patients are connected whenever a service is provided. The structure of this network contains crucial information on the flow of information and the variation of healthcare quality, and thus allows to tackle questions of national importance such as the above.\n de-identified, of course. ^   ","date":1526220000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1526220000,"objectID":"0da383dba0c8f75e8e4dda8b37a4ee17","permalink":"https://strakaps.github.io/project/gp-networks/","publishdate":"2018-05-14T00:00:00+10:00","relpermalink":"/project/gp-networks/","section":"project","summary":"What effect does the social structure of health systems have on health outcomes?","tags":["Healthcare","Python","Networks","Big Data"],"title":"Networks of Health Providers","type":"project"},{"authors":null,"categories":["Software"],"content":"","date":1526220000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1526220000,"objectID":"83f39ce2a9b1d0c43a499084b8e96eb7","permalink":"https://strakaps.github.io/project/ctre/","publishdate":"2018-05-14T00:00:00+10:00","relpermalink":"/project/ctre/","section":"project","summary":"Models extremes of bursty time series.","tags":["R","R package","Software"],"title":"R package CTRE","type":"project"},{"authors":null,"categories":["software"],"content":"The new R package CTRE is now available on CRAN. “CTRE” stands for “Continuous Time Random Exceedances”, which is a model for extreme values of bursty time series. The theory is desribed in another paper (html|pdf).\nlibrary(CTRE) flares_ctre \u0026lt;- ctre(flares) plot(flares_ctre, log = \u0026quot;y\u0026quot;, main = \u0026quot;Solar Flares\u0026quot;) The above time series are measurements of solar flare magnitudes by NASA1. Which observations are considered extreme is defined by a variable threshold \\(u\\) (dashed line, \\(\u0026lt; 5\\%\\) of observations). The exceedances of this threshold (red) follow (asymptotically for high \\(u\\)) a Generalized Pareto distribution. This type of modelling of extremes is standard in Extreme Value Theory, and known as the Peaks Over Threshold (POT) method. To date, 18 R packages have been developed for POT!\nWhat’s new about CTRE? CTRE provides a new way to model the bursty timing of the threshold crossings. In complex systems, inter-event times are typically heavy-tailed2, and thus highly heterogeneous (think income distributions). The bulk of inter-event times is short, corresponding to Bursts of events. A few very long inter-event times represent quiet periods.\nThe Mittag-Leffler distribution is universal for times between threshold crossings, see the companion paper. CTRE fits a Mittag-Leffler distribution to a range of threshold values:\nflares_ctre \u0026lt;- thin(flares_ctre, k = 700) par(mfrow = c(1,2)) MLestimates(flares_ctre, tail = 0.9, scale = 3E7) Above, the threshold is varied from the 5th to the 700th largest magnitude (as you move right along the x-axes) and the parameters estimates are plotted on the y-axis. For both panels, towards the left (exceedances=5), only few data are available, and the estimate has a high variance. Towards the right (exceedances = 700), the threshold is low, and the Mittag-Leffler fit degrades (high bias). In between is where we want to read off our (hopefully stable) parameter estimates. The above plots are hence called “stability plots”.\n Important: The scale parameter is proportional to \\(k^{-1/\\beta}\\). The parameter \\(\\beta\\) is hence used to rescale the y-values of the right-hand plot, in order to make the estimates constant, and needs to estimated from the left-hand plot first.\n   CTRE applied to data For the solar flare data, we read off \\[ \\beta \\approx 0.9, \\quad \\sigma \\approx 3 \\times 10^7. \\] This means that the inter-arrival time \\(T(k)\\) for magnitudes as high as the \\(k\\)-th magnitude is distributed as \\[ T(k) \\sim {\\rm ML}\\left(0.9, \\frac{3 \\times 10^7 {\\rm sec}}{k^{1/0.9}} \\right). \\] For example, let’s assume the magnitude (peak rate) \\(10,000\\). How many magnitudes exceed it?\nlibrary(magrittr) (flares_ctre %\u0026gt;% magnitudes() %\u0026gt;% sort(decreasing=TRUE) \u0026gt; 10000) %\u0026gt;% sum() ## [1] 24 So substitute \\(k = 24\\). The model thus predicts inter-arrival times drawn from the distribution \\[ {\\rm ML}\\left(0.9, 8.8\\times 10^{5} {\\rm sec} \\right) = {\\rm ML}\\left(0.9, 10 {\\rm days} \\right). \\]\nHere’s the plot of this distribution, on a logarithmic scale:\nCompared to the Exponential distribution, the Mittag-Leffler distribution puts more probability mass on both tiny values (Bursts) and values in the tails (quiet periods).\n Shiny app Running\nCTRE::runCTREshiny() opens a Shiny app that that lets you do the above manipulations via sliders. It is / should be loading below:\n  What about “clustering of extremes”? The main other appraoch in Extreme Value Theory which addresses irregular (non-Poissonian) threshold crossing times goes under the name “clustering of extremes”.3 It assumes that the underlying process is stationary, and conflates each excursion of the process above the threshold as one cluster of events.\nCTREs and clustering of extremes both generalize the standard assumption of independent events, but in different directions. They are hence complementary, and it needs to be investigated how they should be compared meaningfully.\n Feedback Do you think CTREs are a useful model? Please comment below.\n  The “complete Hard X Ray Burst Spectrometer event list” is a comprehensive reference for all measurements of the Hard X Ray Burst Spectrometer on NASA’s Solar Maximum Mission from the time of launch on Feb 14, 1980 to the end of the mission in Dec 1989. 12,776 events were detected, with the “vast majority being solar flares”. The list includes the start time, peak time, duration, and peak rate of each event. We have used “start time” as the variable for event times, and “peak rate” as the variable for event magnitudes.↩\n See the Introduction of “Modelling bursty time series” by Vajna, Tóth \u0026amp; Kertész, for a list of complex systems with heavy-tailed inter-event times.↩\n See e.g. Chapter 3 in the textbook Extremes and Related Properties of Random Sequences and Processes by Leadbetter, Lindgren \u0026amp; Rootzén.↩\n   ","date":1525996800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525996800,"objectID":"cb33b580263aa2b9ce4ca4cc9f2a6388","permalink":"https://strakaps.github.io/post/ctre-package/","publishdate":"2018-05-11T00:00:00Z","relpermalink":"/post/ctre-package/","section":"post","summary":"The R package is now available on CRAN. It Models extremes of 'bursty'\ntime series via Continuous Time Random Exceedances (CTRE).\n(See [companion paper](https://strakaps.github.io/bursty-POT/).)\n","tags":["software","bursts","extremes","heavy-tails","R","R-package"],"title":"R package CTRE: thresholding bursty time series","type":"post"},{"authors":["Katharina Hees, Smarak Nayak, Peter Straka"],"categories":null,"content":"","date":1524837600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1524837600,"objectID":"33529ea2ead5e1f8a165840cb7bc75ff","permalink":"https://strakaps.github.io/publication/bursty-pot/","publishdate":"2018-04-28T00:00:00+10:00","relpermalink":"/publication/bursty-pot/","section":"publication","summary":"In many complex systems studied in statistical physics, inter-arrival times between events such as solar flares, trades and neuron voltages follow a heavy-tailed distribution. The set of event times is fractal-like, being dense in some time windows and empty in others, a phenomenon which has been dubbed 'bursty'. This article generalizes the Peaks Over Threshold (POT) model to the setting where inter-event times are heavy-tailed. For high thresholds and infinite-mean waiting times, we show that the times between threshold crossings are Mittag-Leffler distributed, and thus form a 'fractional Poisson Process' which generalizes the standard Poisson Process. We provide graphical means of estimating model parameters and assessing model fit. Along the way, we apply our inference method to a real-world bursty time series, and show how the memory of the Mittag-Leffler distribution affects the predictive distribution for the time until the next extreme event.","tags":null,"title":"Peaks Over Threshold for Bursty Time Series","type":"publication"},{"authors":null,"categories":["Statistical Physics"],"content":"The new paper (arxiv.org/abs/1712.06767)\n Variable Order Fractional Fokker-Planck Equations derived from Continuous Time Random Walks\n is currently under review.\nThe variable order fractional Fokker-Planck equation (VOFFPE), in simple form1, is \\[\\frac{\\partial}{\\partial t} p(x,t) = \\frac{\\partial^2}{\\partial x^2} \\underbrace{D_t^{1-\\beta(x)}}_{\\text{fractional derivative}} p(x,t).\\]\n If you take out the fractional derivative operator, you get the Fokker-Planck equation (FPE). It describes the spreading of probability via a random walk:    Adding in the fractional derivative \\[D_t^{1-\\beta} p(x,t) = \\int_0^t p(x,t-s) \\frac{s^{-\\beta}}{\\Gamma(1-\\beta)}\\,ds\\] results in the “fractional FPE”. The fractional derivative corresponds to longs rests of a walker, and slows down the spreading (making the dynamics “sub”diffusive).\n Here the order \\(1-\\beta\\) of the fractional derivative varies with the location \\(x\\) of the walker, hence the name VOFFPE (variable order fractional FPE). In some regions, e.g. where the intracellular matrix of a cell is dense2, the trappingness can be stronger, which is modelled by a smaller \\(\\beta(x)\\) in that region.\n  The paper shows that the equation has a unique solution \\(p(x,t)\\), and that this solution is the probability distribution of a Continuous Time Random Walk (CTRW)3. CTRWs are random walks with random waiting times between jumps:\n The fractional derivative in time is tightly linked with Mittag-Leffler distributed waiting times.\nOf course CTRWs can be simulated, and \\(p(x,t)\\) may be computed via Monte Carlo simulations (or “particle tracking”). Thus a consequence of the paper is the mathematical certainty that the variable order FFPE (VOFFPE) can be solved by simulations.\nThe variable order FFPE can also be solved directly, via clever numerical algorithms. The CTRW interpretation of the VOFFPE can be leveraged for such a clever numerical algorithm, as our friends over in applied maths have done with their Discrete Time Random Walk algorithm. This approach has several great benefits4, and now we know how to extend these benefits to the variable order setting (to be continued).\n Drift and diffusivity are left out here, but they may be any (Lipschitz-) continuous functions.↩\n Wong et. al, PRL 2004↩\n Strictly speaking, a scaling limit of a CTRW.↩\n E.g. conservation of mass and non-negative solutions.↩\n   ","date":1513555200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1513555200,"objectID":"061f502262daef1477f04c6d394e12c6","permalink":"https://strakaps.github.io/post/voffpe/","publishdate":"2017-12-18T00:00:00Z","relpermalink":"/post/voffpe/","section":"post","summary":"A Fractional Fokker-Planck Equation is derived which scales\nvariably in space. The paper is now\n[published](https://doi.org/10.1016/j.physa.2018.03.010).\n","tags":["Statistical Physics","Anomalous Diffusion","Probability","Stochastic Processes","Publication"],"title":"Fractional Diffusion where \"fractional\" varies in space","type":"post"},{"authors":null,"categories":["Software"],"content":"Ricky Gill and I have created the R package MittagLeffleR, documented at strakaps.github.io/MittagLeffleR/. It is available on CRAN (and the latest development version on GitHub). MittagLeffleR calculates both Mittag-Leffler distributions; i.e. probability density, cumulative distribution function, quantile function and fast random variate generation. It was made possible by the Laplace inversion algorithm for the Mittag-Leffler function by Roberto Garrappa. Install it via\ninstall.packages(\u0026quot;MittagLeffleR\u0026quot;) The Two Mittag-Leffler distributions Various journal articles (including my own) write about “the” Mittag-Leffler distribution, but actually there are two such families of distributions. Both have a shape parameter (tail) taken from the interval \\((0,1]\\), but the first distribution is very heavy-tailed with infinite mean if tail \\(\\in (0,1)\\) (it is equal to the exponential distribution if tail \\(=1\\)) whereas the second distribution is light-tailed (has finite moments of all orders). The boolean variable second.type switches between these two distributions.\n Examples First type = waiting times between events The first type Mittag-Leffler distribution commonly occurs for the inter-arrival times between events in complex systems (e.g. earthquakes, see future post). Suppose that for an event to happen, several “tries” are needed, and that each try has a duration. The number \\(N\\) of tries until a success is geometrically distributed, and the sum of \\(N\\) durations is well approximated by a Mittag-Leffler (type I) distribution (this is the geometric stable property).\nAs an example, we simulate n=100 Mittag-Leffler (type I) random variables, and estimate their tail and scale parameters via maximum likelihood:\nlibrary(MittagLeffleR) y = rml(n = 100, tail = 0.9, scale = 2) mlml \u0026lt;- function(X) { log_l \u0026lt;- function(theta) { #transform parameters so can do optimization unconstrained theta[1] \u0026lt;- 1/(1+exp(-theta[1])) theta[2] \u0026lt;- exp(theta[2]) -sum(log(dml(X,theta[1],theta[2]))) } ml_theta \u0026lt;- stats::optim(c(0.5,0.5), fn=log_l)$par #transform back ml_a \u0026lt;- 1/(1 + exp(-ml_theta[1])) ml_d \u0026lt;- exp(ml_theta[2]) return(list(\u0026quot;tail\u0026quot; = ml_a, \u0026quot;scale\u0026quot; = ml_d)) } mlml(y) ## $tail ## [1] 0.9390633 ## ## $scale ## [1] 1.600294  Second type = number of events The second type Mittag-Leffler distribution typically occurs for the random number of events in complex systems. For instance, assume a random walk with heavy-tailed waiting times; this has become a widely adopted model for anomalous diffusion. For late times, its number of steps can be well approximated by a Mittag-Leffler (type II) distribution.\nThe time-change of a random walk by the random number of steps is called subordination; the random number of steps is approximated by the inverse stable subordinator. Below we calculate the probability density of a random walker with step size dx=0.01:\n the number of steps up to time \\(t\\) is stored in the vector \\(h\\) the matrix \\(N\\) stores the probability distribution at the lattice sites at consecutive times the “subordination” happens in the matrix product N %*% h.  library(MittagLeffleR) tail \u0026lt;- 0.65 dx \u0026lt;- 0.01 x \u0026lt;- seq(-2,5,dx) umax \u0026lt;- qml(p=0.99, tail=tail, scale=1, second.type=TRUE) u \u0026lt;- seq(0.01,umax,dx) h \u0026lt;- dml(x=u, tail=tail, scale=1, second.type=TRUE) N \u0026lt;- outer(x,u,function(x,u){dnorm(x=x, mean=u, sd=sqrt(u))}) p \u0026lt;- N %*% h * dx plot(x,p, type=\u0026#39;l\u0026#39;, main=\u0026quot;Fractional diffusion with drift at t=1\u0026quot;)   Bugs and Issues Should you run into any bugs or issues, please let us know. Thanks!\n ","date":1498435200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498435200,"objectID":"14bc1a9346879cd0ba6670c380e9e54d","permalink":"https://strakaps.github.io/post/mittag-leffler/","publishdate":"2017-06-26T00:00:00Z","relpermalink":"/post/mittag-leffler/","section":"post","summary":"First version of an R package which calculates probability densities\nof the Mittag-Leffler families of distributions.\n","tags":["Software","R","R package","Heavy Tails","Bursts"],"title":"R package MittagLeffleR: Using the Mittag-Leffler distributions in R","type":"post"},{"authors":null,"categories":["recruitment"],"content":" It is my pleasure to announce that applications for the prestigious UNSW Scientia Ph.D. Scholarship Scheme on the project \u0026ldquo;Using Big Data to Redesign the Health System\u0026rdquo; are now open.\nThe UNSW Scientia Ph.D. Scholarship Scheme is the most prestigious and generous scholarship scheme at UNSW and it aims to attract the best and brightest people into strategic research areas. Awardees receive a $50,000 scholarship package for four years, comprising a $40,000 per annum tax-free stipend and a travel and development support package of up to $10,000 per annum. International students also receive a tuition fee scholarship.\nIn addition to this scholarship package, scholars are provided with access to a range of development opportunities across research, teaching and learning and leadership and engagement.\nApplicants should submit their expression of interest at\nhttp://www.2025.unsw.edu.au/apply/scientia-phd-scholarships/using-Big Data-redesign-health-system\nby 21st July 2017 but are encouraged to do so as early as possible.\nMore information on the UNSW Scientia PhD Scholarship Scheme:\n General info: http://www.2025.unsw.edu.au/apply/ Guidelines: http://www.2025.unsw.edu.au/apply/node/69/ FAQs: http://www.2025.unsw.edu.au/apply/unsw-scientia-phd-scholarships-faqs  The Project: Health services are working to develop new models for care that keep people out of hospital, such as community outreach, daily outpatient assessment and hospital in the home. Identifying patient subgroups (\u0026lsquo;phenotypes\u0026rsquo;) with distinct characteristics that are predictive of their subsequent outcomes (e.g. admission, complications) is key to designing these new models. Machine learning (ML) techniques are data-driven approaches that can discover statistical patterns in high-dimensional, multivariate data sets. This project will apply ML techniques to health \u0026lsquo;big data\u0026rsquo; to identify patient phenotypes that will support the design and implementation of new tailored care pathways for patients with chronic disease.\nSupervisory Team Prof Louisa Jorm (Director, Centre for Big Data Research in Health) and myself. Please contact either of us for more details.\n","date":1497189600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497189600,"objectID":"1607e9d773d359696a3d237faa3a88f4","permalink":"https://strakaps.github.io/post/scientia-phd/","publishdate":"2017-06-12T00:00:00+10:00","relpermalink":"/post/scientia-phd/","section":"post","summary":"Apply for a prestigious PhD scholarship.","tags":["Announcement","Scholarship","PhD"],"title":"Prestigious Scientia PhD Scholarship available","type":"post"},{"authors":null,"categories":["Software"],"content":"","date":1493215200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493215200,"objectID":"f7bfad4ac7cdb5976a8dc8c62104fb7c","permalink":"https://strakaps.github.io/project/mittagleffler/","publishdate":"2017-04-27T00:00:00+10:00","relpermalink":"/project/mittagleffler/","section":"project","summary":"Computes Mittag-Leffler probability densities.","tags":["R","R package","Software"],"title":"R package MittagLeffleR","type":"project"},{"authors":["Gurtek Gill, Peter Straka"],"categories":null,"content":"","date":1483189200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483189200,"objectID":"a185dc43b2ab43ce8259c80fee60cf1b","permalink":"https://strakaps.github.io/publication/semi-markov-algo/","publishdate":"2017-01-01T00:00:00+11:00","relpermalink":"/publication/semi-markov-algo/","section":"publication","summary":"The Semi-Markov property of Continuous Time Random Walks (CTRWs) and their limit processes is utilized, and the probability distributions of the bivariate Markov process (X(t),V(t)) are calculated: X(t) is a CTRW limit and V(t) a process tracking the age, i.e. the time since the last jump. For a given CTRW limit process X(t), a sequence of discrete CTRWs in discrete time is given which converges to X(t) (weakly in the Skorokhod topology). Master equations for the discrete CTRWs are implemented numerically, thus approximating the distribution of X(t). A consequence of the derived algorithm is that any distribution of initial age can be assumed as an initial condition for the CTRW limit dynamics. Four examples with different temporal scaling are discussed: subdiffusion, tempered subdiffusion, the fractal mobile/immobile model and the tempered fractal mobile/immobile model.","tags":null,"title":"A semi-markov algorithm for continuous time random walk limit distributions","type":"publication"},{"authors":["Boris Baeumer, Peter Straka"],"categories":null,"content":"","date":1483189200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483189200,"objectID":"e106e3993d18d05702c7b70b1ec8b9cc","permalink":"https://strakaps.github.io/publication/forward-backward-ffpe/","publishdate":"2017-01-01T00:00:00+11:00","relpermalink":"/publication/forward-backward-ffpe/","section":"publication","summary":"It is proved that the distributions of scaling limits of Continuous Time Random Walks (CTRWs) solve integro-differential equations akin to Fokker-Planck equations for diffusion processes. In contrast to previous such results, it is not assumed that the underlying process has absolutely continuous laws. Moreover, governing equations in the backward variables are derived. Three examples of anomalous diffusion processes illustrate the theory.","tags":null,"title":"Fokker–Planck and Kolmogorov backward equations for continuous time random walk scaling limits","type":"publication"},{"authors":null,"categories":["Anomalous Diffusion"],"content":"Diffusion is the net movement of molecules or atoms from a region of high concentration to a region of low concentration as a result of random motion of the molecules or atoms (Wikipedia).\nDue to a discovery by Einstein (1905), a universal model for the random motion of microscopic particles is Brownian motion, whose mean-squared displacement increases linearly with time.\nIn many system with particles more complex than tiny molecules which interact with their environment (e.g. proteins, self-propelled bacteria or cells, stock market prices, \u0026hellip;) the growth of the mean-squared displacement is no longer linear:\n(Image credit Wikipedia).\nThe Continuous Time Random Walk (CTRW) is a model for anomalous diffusion: it can model subdiffusion with long (heavy-tailed) waiting times between steps, and superdiffusion with long (heavy-tailed) steps, and even a mixture of both.\nScientists are interested in extending the CTRW model to allow for interactions between walkers, and need tools for the computation of concentrations of random walkers. Since the beginning of the century, there has been a fruitful exchange between statistical physics, experimental physics, pure mathematics and computational mathematics, which has significantly advanced biophysics, among other fields.\n","date":1461679200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461679200,"objectID":"ceb61b9025dc879b738824a027c02a48","permalink":"https://strakaps.github.io/project/anomalous-diffusion/","publishdate":"2016-04-27T00:00:00+10:00","relpermalink":"/project/anomalous-diffusion/","section":"project","summary":"Limit theorems and statistical physics","tags":["Anomalous Diffusion"],"title":"Continuous Time Random Walks","type":"project"},{"authors":null,"categories":["Statistical Physics"],"content":"Extreme value theory is concerned with the modelling and prediction of extremes in a series of observations. Accurate estimates of probabilities for the exceedence of extreme levels of temperature, financial loss, the number of defective nodes in a network etc. are crucial for the control of risk in a great number of societal systems. \u0026ldquo;Mainstream\u0026rdquo; extreme value theory assumes that events happen uniformly, e.g. yearly, daily, or every second, or that events occur at a certain rate (Poisson process). In fact, however, a great number of systems violates this assumption: Events occur in Bursts, intermittent with quiescent periods drawn from a heavy-tailed distribution. This phenomenon is ubiquitous for human-created events, and is deemed to occur for any type of action resulting from a dynamic list of priorities.\nOften a magnitude, or mark can be assigned to each event in the renewal process, such as for earthquakes, solar flares, neuron voltages etc. The Peaks-Over-Threshold model (POT, see e.g. Coles 2001) applies a threshold to the magnitudes, and fits a Generalized Pareto distribution to the threshold exceedances. The timing of the threshold exceedances fits well with a \u0026ldquo;Poisson process\u0026rdquo;, i.e. the threshold crossing times are distributed completely randomly on the given time interval.\nFor bursty data, the Poisson process representation is no long valid, but a fractional Poisson process representation holds. This project derives the theoretical model behind the timings of bursty threshold crossings, statistical methods for the fitting of the model, and R software packages for applications to data.\n","date":1461679200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461679200,"objectID":"78e129309383006a2e202afc85fab9e7","permalink":"https://strakaps.github.io/project/bursts/","publishdate":"2016-04-27T00:00:00+10:00","relpermalink":"/project/bursts/","section":"project","summary":"Heavy tails, scaling limits, R packages","tags":["Bursts","Statistics","Statistical Physics"],"title":"Extremes of Bursty Time Series","type":"project"},{"authors":null,"categories":["Healthcare"],"content":"Records of antidepressant dispensings are often used in public health research as a surrogate measure of depression. In 1\u0026frasl;3 to 1\u0026frasl;2 of cases however, antidepressants are prescribed for indications other than depression, which results in misclassification.\nMedicare Benefits Schedule (MBS) data contain the dispensings of antidepressants and other pharmaceuticals, and data from the 45 and Up Study provide a gold standard response variable (a yes/no answer to \u0026ldquo;Have you been treated for depression?\u0026rdquo;).\nHow can these data be used to design a predictive algorithm identifying antidepressant users with depression?\n","date":1461679200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461679200,"objectID":"f1f814f4b6f1c785757f28b1cfffe4fb","permalink":"https://strakaps.github.io/project/antidepressants/","publishdate":"2016-04-27T00:00:00+10:00","relpermalink":"/project/antidepressants/","section":"project","summary":"Only 1/2 -- 2/3 of antidepressant users have depression. How do we use statistical learning to predict depression given antidepressant use?","tags":["Statistics","Healthcare","R"],"title":"Identifying antidepressant users with depression","type":"project"},{"authors":["Boris Baeumer, Mihály Kovács, Mark M. Meerschaert, René L. Schilling and Peter Straka"],"categories":null,"content":"","date":1451566800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451566800,"objectID":"dfa8c4b1f4c8e4f43bce65188c4132d5","permalink":"https://strakaps.github.io/publication/reflected-stable/","publishdate":"2016-01-01T00:00:00+11:00","relpermalink":"/publication/reflected-stable/","section":"publication","summary":"This paper explicitly computes the transition densities of a spectrally negative stable process with index greater than one, reflected at its infimum. First we derive the forward equation using the theory of sun-dual semigroups. The resulting forward equation is a boundary value problem on the positive half-line that involves a negative Riemann-Liouville fractional derivative in space, and a fractional reflecting boundary condition at the origin. Then we apply numerical methods to explicitly compute the transition density of this space-inhomogeneous Markov process, for any starting point, to any desired degree of accuracy. Finally, we discuss an application to fractional Cauchy problems, which involve a positive Caputo fractional derivative in time.","tags":null,"title":"Reflected spectrally negative stable processes and their governing equations","type":"publication"},{"authors":["M.Magdziarz, H.P.Scheffler, P.Straka, P.Zebrowski"],"categories":null,"content":"","date":1446296400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1446296400,"objectID":"7e80e3776908176c19455f30c591cd1d","permalink":"https://strakaps.github.io/publication/levy-walk/","publishdate":"2015-11-01T00:00:00+11:00","relpermalink":"/publication/levy-walk/","section":"publication","summary":"The Lévy Walk is the process with continuous sample paths which arises from consecutive linear motions of i.i.d. lengths with i.i.d. directions. Assuming speed  and motions in the domain of -stable attraction, we prove functional limit theorems and derive governing pseudo-differential equations for the law of the walker’s position. Both Lévy Walk and its limit process are continuous and ballistic in the case . In the case , the scaling limit of the process is -stable and hence discontinuous. This result is surprising, because the scaling exponent  on the process level is seemingly unrelated to the scaling exponent  of the second moment. For , the scaling limit is Brownian motion.","tags":null,"title":"Limit theorems and governing equations for Lévy walks","type":"publication"},{"authors":["Evgeny Spodarev, Peter Straka, Steffen Winter"],"categories":null,"content":"","date":1433080800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1433080800,"objectID":"27ace9760a04809e3f5005ee8d7ce267","permalink":"https://strakaps.github.io/publication/frac-curv/","publishdate":"2015-06-01T00:00:00+10:00","relpermalink":"/publication/frac-curv/","section":"publication","summary":"Most of the known methods for estimating the fractal dimension of fractal sets are based on the evaluation of a single geometric characteristic, e.g. the volume of its parallel sets. We propose a method involving the evaluation of several geometric characteristics, namely all the intrinsic volumes (i.e. volume, surface area, Euler characteristic, etc.) of the parallel sets of a fractal. Motivated by recent results on their limiting behavior, we use these functionals to estimate the fractal dimension of sets from digital images. Simultaneously, we also obtain estimates of the fractal curvatures of these sets, some fractal counterpart of intrinsic volumes, allowing a finer classification of fractal sets than by means of fractal dimension only. We show the consistency of our estimators and test them on some digital images of self-similar sets.","tags":null,"title":"Estimation of fractal dimension and fractal curvatures from digital images","type":"publication"},{"authors":["P. Straka, S. Fedotov"],"categories":null,"content":"","date":1423227600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1423227600,"objectID":"770521013df2f6270faf35dcfa7384aa","permalink":"https://strakaps.github.io/publication/subdiffusion-interaction/","publishdate":"2015-02-07T00:00:00+11:00","relpermalink":"/publication/subdiffusion-interaction/","section":"publication","summary":"We show how the nonlinear interaction effects ‘volume filling’ and ‘adhesion’ can be incorporated into the fractional subdiffusive transport of cells and individual organisms. To this end, we use microscopic random walk models with anomalous trapping and systematically derive generic non-Markovian and nonlinear governing equations for the mean concentrations of the subdiffusive cells or organisms. We uncover an interesting interaction between the nonlinearities and the non-Markovian nature of the transport. In the subdiffusive case, this interaction manifests itself in a nontrivial combination of nonlinear terms with fractional derivatives. In the long time limit, however, these equations simplify to a form without fractional operators. This provides an easy method for the study of aggregation phenomena. In particular, this enables us to show that volume filling can prevent “anomalous aggregation,” which occurs in subdiffusive systems with a spatially varying anomalous exponent.","tags":null,"title":"Transport equations for subdiffusion with nonlinear particle interaction","type":"publication"},{"authors":["C. N. Angstmann, I. C. Donnelly, B. I. Henry, T. A. M. Langlands, and P. Straka"],"categories":null,"content":"","date":1420030800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420030800,"objectID":"7e8cc0975e127210a88708fee3503e68","permalink":"https://strakaps.github.io/publication/ctrw-timing/","publishdate":"2015-01-01T00:00:00+11:00","relpermalink":"/publication/ctrw-timing/","section":"publication","summary":"Continuous time random walks, which generalize random walks by adding a stochastic time between jumps, provide a useful description of stochastic transport at mesoscopic scales. The continuous time random walk model can accommodate certain features, such as trapping, which are not manifest in the standard macroscopic diffusion equation. The trapping is incorporated through a waiting time density, and a fractional diffusion equation results from a power law waiting time. A generalized continuous time random walk model with biased jumps has been used to consider transport that is also subject to an external force. Here we have derived the master equations for continuous time random walks with space- and time-dependent forcing for two cases: when the force is evaluated at the start of the waiting time and at the end of the waiting time. The differences persist in low order spatial continuum approximations; however, the two processes are shown to be governed by the same Fokker--Planck equations in the diffusion limit. Thus the fractional Fokker--Planck equation with space- and time-dependent forcing is robust to these changes in the underlying stochastic process.","tags":null,"title":"Generalized Continuous Time Random Walks, Master Equations, and Fractional Fokker--Planck Equations","type":"publication"},{"authors":["Mark M. Meerschaert and Peter Straka"],"categories":null,"content":"","date":1388494800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388494800,"objectID":"78cf237e4a24391beedb71ff04712e9e","permalink":"https://strakaps.github.io/publication/semi-markov-ctrw/","publishdate":"2014-01-01T00:00:00+11:00","relpermalink":"/publication/semi-markov-ctrw/","section":"publication","summary":"Continuous time random walks (CTRWs) are versatile models for anomalous diffusion processes that have found widespread application in the quantitative sciences. Their scaling limits are typically non-Markovian, and the computation of their finite-dimensional distributions is an important open problem. This paper develops a general semi-Markov theory for CTRW limit processes in ℝd with infinitely many particle jumps (renewals) in finite time intervals. The particle jumps and waiting times can be coupled and vary with space and time. By augmenting the state space to include the scaling limits of renewal times, a CTRW limit process can be embedded in a Markov process. Explicit analytic expressions for the transition kernels of these Markov processes are then derived, which allow the computation of all finite dimensional distributions for CTRW limits. Two examples illustrate the proposed method.","tags":null,"title":"Semi-Markov approach to continuous time random walk limit processes","type":"publication"},{"authors":["Mark M. Meerschaert and Peter Straka"],"categories":null,"content":"","date":1366725600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1366725600,"objectID":"d7c52cbb4c777f3de235ac6a040baf58","permalink":"https://strakaps.github.io/publication/inv-stable-subord/","publishdate":"2013-04-24T00:00:00+10:00","relpermalink":"/publication/inv-stable-subord/","section":"publication","summary":"The inverse stable subordinator provides a probability model for time-fractional differential equations, and leads to explicit solution formulae. This paper reviews properties of the inverse stable subordinator, and applications to a variety of problems in mathematics and physics. Several different governing equations for the inverse stable subordinator have been proposed in the literature. This paper also shows how these equations can be reconciled.","tags":null,"title":"Inverse stable subordinators","type":"publication"},{"authors":["Peter Straka, Mark M. Meerschaert, Robert J. McGough, Yuzhen Zhou"],"categories":null,"content":"","date":1362056400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1362056400,"objectID":"effeb5f254c4049cef402a38cdd6315d","permalink":"https://strakaps.github.io/publication/wave-attenuation/","publishdate":"2013-03-01T00:00:00+11:00","relpermalink":"/publication/wave-attenuation/","section":"publication","summary":"Fractional wave equations with attenuation have been proposed by Caputo [5], Szabo [28], Chen and Holm [7], and Kelly et al. [11]. These equations capture the power-law attenuation with frequency observed in many experimental settings when sound waves travel through inhomogeneous media. In particular, these models are useful for medical ultrasound. This paper develops stochastic solutions and weak solutions to the power law wave equation of Kelly et al. [11].","tags":null,"title":"Fractional wave equations with attenuation","type":"publication"},{"authors":["Mark M. Meerschaert and Peter Straka"],"categories":null,"content":"","date":1351688400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1351688400,"objectID":"4f2fe273e063ea249a0f11ff8b239649","permalink":"https://strakaps.github.io/publication/ctrw-fdd/","publishdate":"2012-11-01T00:00:00+11:00","relpermalink":"/publication/ctrw-fdd/","section":"publication","summary":"A continuous time random walk (CTRW) imposes a random waiting time between random particle jumps. CTRW limit densities solve a fractional Fokker-Planck equation, but since the CTRW limit is not Markovian, this is not sufficient to characterize the process. This paper applies continuum renewal theory to restore the Markov property on an expanded state space, and compute the joint CTRW limit density at multiple times.","tags":null,"title":"Fractional Dynamics at Multiple Times","type":"publication"},{"authors":["Mark M Meerschaert, Peter Straka, Yuzhen Zhou, Robert J McGough"],"categories":null,"content":"","date":1349013600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1349013600,"objectID":"78394ac8548014eeb708936759121c9f","permalink":"https://strakaps.github.io/publication/frac-wave/","publishdate":"2012-10-01T00:00:00+10:00","relpermalink":"/publication/frac-wave/","section":"publication","summary":"The power law wave equation uses two different fractional derivative terms to model wave propagation with power law attenuation. This equation averages complex nonlinear dynamics into a convenient, tractable form with an explicit analytical solution. This paper develops a random walk model to explain the appearance and meaning of the fractional derivative terms in that equation, and discusses an application to medical ultrasound. In the process, a new strictly causal solution to this fractional wave equation is developed.","tags":null,"title":"Stochastic solution to a time-fractional attenuated wave equation","type":"publication"},{"authors":["B. I. Henry, T. A. M. Langlands and P. Straka"],"categories":null,"content":"","date":1296478800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1296478800,"objectID":"0dd51b8a0ab1109000399e21632bafe1","permalink":"https://strakaps.github.io/publication/hls-prl/","publishdate":"2011-02-01T00:00:00+11:00","relpermalink":"/publication/hls-prl/","section":"publication","summary":"We derive a fractional Fokker-Planck equation for subdiffusion in a general space- and time-dependent force field from power law waiting time continuous time random walks biased by Boltzmann weights. The governing equation is derived from a generalized master equation and is shown to be equivalent to a subordinated stochastic Langevin equation.","tags":null,"title":"Fractional Fokker-Planck Equations for Subdiffusion with Space- and Time-Dependent Forces","type":"publication"},{"authors":["Peter Straka and Bruce Henry"],"categories":null,"content":"","date":1296478800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1296478800,"objectID":"3df8b0a7f38f6d82ba4507cdb3d2543a","permalink":"https://strakaps.github.io/publication/lagging-leading-ctrw/","publishdate":"2011-02-01T00:00:00+11:00","relpermalink":"/publication/lagging-leading-ctrw/","section":"publication","summary":"Subordinating a random walk to a renewal process yields a continuous time random walk (CTRW), which models diffusion and anomalous diffusion. Transition densities of scaling limits of power law CTRWs have been shown to solve fractional Fokker–Planck equations. We consider limits of CTRWs which arise when both waiting times and jumps are taken from an infinitesimal triangular array. Two different limit processes are identified when waiting times precede jumps or follow jumps, respectively, together with two limit processes corresponding to the renewal times. We calculate the joint law of all four limit processes evaluated at a fixed time t.","tags":null,"title":"Lagging and leading coupled continuous time random walks, renewal times and their joint limits","type":"publication"},{"authors":["B. I. Henry, T. A. M. Langlands and P. Straka"],"categories":null,"content":"","date":1262264400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1262264400,"objectID":"ab0ed9627a1cc3e154c4bce761d17dc2","permalink":"https://strakaps.github.io/publication/hls-intro/","publishdate":"2010-01-01T00:00:00+11:00","relpermalink":"/publication/hls-intro/","section":"publication","summary":"The mathematical description of diffusion has a long history with many different formulations including phenomenological models based on conservation of mass and constitutive laws; probabilistic models based on random walks and central limit theorems; microscopic stochastic models based on Brownian motion and Langevin equations; and mesoscopic stochastic models based on master equations and Fokker–Planck equations. A fundamental result common to the different approaches is that the mean square displacement of a diffusing particle scales linearly with time. However there have been numerous experimental measurements in which the mean square displacement of diffusing particles scales as a fractional order power law in time. In recent years a great deal of progress has been made in extending the different models for diffusion to incorporate this fractional diffusion. The tools of fractional calculus have proven very useful in these developments, linking together fractional constitutive laws, continuous time random walks, fractional Langevin equations and fractional Brownian motions. These notes provide a tutorial style overview of standard and fractional diffusion processes.","tags":null,"title":"An introduction to fractional diffusion","type":"publication"}]